# -*- coding: utf-8 -*-
"""TechChallange 02 (2)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E_42pk8C8ikFP2zTIn-Xe0HXYG5On1MM
"""

import pandas as pd
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import acf, pacf
#Avisos
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv("/content/Dados Históricos - Ibovespa_4anos.csv", sep=",")
df.head(25)

df.info()

df['Data'] = pd.to_datetime(df['Data'])

df.info()

df.head(25)

df = df.rename(columns={"Vol.":"Vol", "Var%":"Var", "Mínima": "Minima", "Máxima": "Maxima", "Último":"Fechamento"})

def convert_to_float(value):
    if "M" in value:
        return float(value.replace("M", "").replace(",", ".")) * 1000000
    elif "K" in value:
        return float(value.replace("K", "").replace(",", ".")) * 1000
    else:
        return float(value.replace(",", "."))

df["Vol"] = df["Vol"].apply(convert_to_float)

print(df)

def convert_to_floats(value):
    return float(value.replace("%", "").replace(",", "."))

df["Var"] = df["Var"].apply(convert_to_floats)

print(df)

df.describe()

df = df.sort_values(by='Data')

df.head()

df.set_index('Data', inplace=True)

df.head()

df.info()

df.isnull().sum()

sns.boxplot(y="Fechamento", data=df, palette="hls")
plt.show()
sns.boxplot(y="Abertura", data=df, palette="hls")
plt.show()
sns.boxplot(y="Maxima", data=df, palette="hls")
plt.show()
sns.boxplot(y="Minima", data=df, palette="hls")
plt.show()
sns.boxplot(y="Vol", data=df, palette="hls")
plt.show()
sns.boxplot(y="Var", data=df, palette="hls")
plt.show()

sns.pairplot(df, vars=['Fechamento','Abertura','Maxima','Minima','Vol', "Var"])

plt.plot(df.index, df["Fechamento"])
plt.xlabel("Data")
plt.ylabel("Fechamento")
plt.title("Média de Fechamento ao Longo do Tempo")
plt.show()

plt.plot(df.index, df["Var"])
plt.xlabel("Data")
plt.ylabel("Volume médio de Invest.")
plt.title("Média de Vol. de Invest. ao Longo do Tempo")
plt.show()

plt.plot(df.index, df["Vol"])
plt.xlabel("Data")
plt.ylabel("Volume médio de Invest.")
plt.title("Média de Vol. de Invest. ao Longo do Tempo")
plt.show()

plt.plot(df.index, df["Minima"])
plt.xlabel("Data")
plt.ylabel("Volume médio de Invest.")
plt.title("Média de Vol. de Invest. ao Longo do Tempo")
plt.show()

correlation_matriz = df.corr().round(2)

fig, ax = plt.subplots(figsize=(8,8))
sns.heatmap(data = correlation_matriz, annot=True, linewidths=5, ax=ax)

plt.scatter(df["Fechamento"], df["Vol"])
plt.xlabel("ultimo")
plt.ylabel("Volume de Investimento")
plt.title("Voume de investimento ao passar do tempo")
plt.show()

plt.scatter(df["Minima"], df["Vol"])
plt.xlabel("Maxima")
plt.ylabel("Volume de Investimento")
plt.title("Voume de investimento ao passar do tempo")
plt.show()

plt.bar(df.index, df["Fechamento"])
plt.xlabel("Data")
plt.ylabel("Voume de investimento")
plt.title("Volume de investimento ao passar do tempo")
plt.show()

print("Data Inicial:", df.index.min())

print("Data Final:", df.index.max())

from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import acf, pacf

"""#*Tendência - Direção
#*Sazonalidade - Recorrência das oscilações
#*Resíduo - O que sobra do sinal
"""

dec_Vol = seasonal_decompose(df['Fechamento'], period=7)

fig, (ax1,ax2,ax3,ax4) = plt.subplots(4,1, figsize=(15,10))
dec_Vol.observed.plot(ax=ax1)
dec_Vol.trend.plot(ax=ax2)
dec_Vol.seasonal.plot(ax=ax3)
dec_Vol.resid.plot(ax=ax4)
plt.tight_layout()

dec_Max = seasonal_decompose(df['Maxima'], period=7)

fig, (ax1,ax2,ax3,ax4) = plt.subplots(4,1, figsize=(15,10))
dec_Max.observed.plot(ax=ax1)
dec_Max.trend.plot(ax=ax2)
dec_Max.seasonal.plot(ax=ax3)
dec_Max.resid.plot(ax=ax4)
plt.tight_layout()

"""#Intentificando Estacionária ou não Estacionária

## Teste ADF - (Augmented Dickey Fuller)

  H0 - Hipótese Nula (não Estacionária)
  
  H1 - Hipótese Alternativa (rejeição da hipótese nula)


p-value = 0.05 (5%) , então rejeitamos H0 com um nível de confiança de 95%
"""

from statsmodels.tsa.stattools import adfuller

df_dickeyF=df.Fechamento.values

R_dickeyF = adfuller(df_dickeyF)

print("teste ABF")
print(f"Teste Estatistico: {R_dickeyF[0]}")
print(f"p-value: {R_dickeyF[1]}")
print(f"Valores Críticos: ")

for key, value in R_dickeyF[4].items():
  print(f"\t{key}: {value}")

df_rol = df["Fechamento"].rolling(12).mean()

f, ax = plt.subplots()
df["Fechamento"].plot(ax=ax, legend=False)
df_rol.plot(ax=ax, legend=False, color="r")
plt.tight_layout()

"""#PROPHET - Meta --> analise de time series
https://facebook.github.io/prophet/docs/quick_start.html#python-api
"""

from prophet import Prophet

df_prof=pd.read_csv("/content/Dados Históricos - Ibovespa_4anos.csv", sep=",")
df_prof.head()

df_prof = df_prof[['Data', 'Último']]
df_prof

df_prof.rename(columns={'Data': 'ds', "Último":"y"}, inplace=True)
df_prof

df_prof1 = Prophet()
df_prof1.fit(df_prof)

future = df_prof1.make_future_dataframe(periods=1095)
future.tail()

forecast = df_prof1.predict(future)
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()

fig1 = df_prof1.plot(forecast)

fig2 = df_prof1.plot_components(forecast)

from prophet.plot import plot_plotly, plot_components_plotly

plot_plotly(df_prof1, forecast)

plot_components_plotly(df_prof1, forecast)

from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import pandas as pd

from prophet.diagnostics import performance_metrics
from prophet.diagnostics import cross_validation
df_cv = cross_validation(df_prof1, initial='395 days', period='180 days', horizon = '1000 days')

df_cv.head()

df_p = performance_metrics(df_cv)
df_p.head()

from prophet.plot import plot_cross_validation_metric
fig = plot_cross_validation_metric(df_cv, metric='mape')

"""#Forecasting"""

df_1=pd.read_csv("/content/Dados Históricos - Ibovespa_4anos.csv", sep=",")
df_1.head()

def convert_to_float(value):
    if "M" in value:
        return float(value.replace("M", "").replace(",", ".")) * 10000
    elif "K" in value:
        return float(value.replace("K", "").replace(",", ".")) * 10
    else:
        return float(value.replace(",", "."))

df_1["Vol."] = df_1["Vol."].apply(convert_to_float)

print(df_1)

df_1.describe()

df_1.info()

df_1.rename(columns={"Vol.": "Volume"}, inplace=True)

df_1.head()

df_1 = df_1[["Data", "Último", "Volume"]]
df_1 = df_1.rename(columns={"Data": "ds", "Último": "y", "Volume": "unique_id"})

df_1

df_1['ds'] = pd.to_datetime(df_1['ds'])

df_1.info()

!pip install statsforecast

df_1.tail()

treino = df_1.loc[df_1["ds"]<"2022-10-01"]
valid = df_1.loc[(df_1["ds"]>="2022-10-01")&(df_1["ds"]<"2023-02-18")]
h = valid["ds"].nunique() #validação do período "valid" (3meses)

h

def wmape(y_true, y_pred):
  return np.abs(y_true-y_pred).sum()/np.abs(y_true).sum()

from statsforecast import StatsForecast
from statsforecast.models import Naive, SeasonalNaive, SeasonalWindowAverage, AutoARIMA

model = StatsForecast(models=[Naive()], freq="D", n_jobs=-1)
model.fit(treino)

forecast_df = model.predict(h=h, level=[90])
forecast_df = forecast_df.reset_index().merge(valid, on=["ds", "unique_id"], how="left")

wmape1 = wmape(forecast_df["y"].values, forecast_df["Naive"].values)
print(f"WMAPE: {wmape1:.2%}")

model.plot(treino, forecast_df, level=[90], unique_ids=forecast_df["unique_id"], engine="matplotlib", max_insample_length=90)

